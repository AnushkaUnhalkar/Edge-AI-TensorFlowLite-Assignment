ğŸš€ Mobile & Edge AI Project
TensorFlow Lite Model Conversion & Edge Deployment (Raspberry Pi Simulation)

ğŸ“Œ Project Overview
This assignment demonstrates:
âœ… Converting a TensorFlow model to TensorFlow Lite
âœ… Running a .tflite model locally
âœ… Simulating Edge AI execution (Raspberry Pi environment)
âœ… Performing inference using TensorFlow Lite
âœ… Comparing performance between PC and Raspberry Pi

ğŸ”¹ PART A â€“ Project 1
TensorFlow Model Conversion to TensorFlow Lite

ğŸ¯ Objective
Convert a TensorFlow SavedModel into a lightweight .tflite model for edge deployment.

ğŸ“‚ Project Structure
Mobile_Edge_AI_Project/
â”‚
â”œâ”€â”€ mobilenet_saved_model/
â”œâ”€â”€ mobilenet_model.tflite
â”œâ”€â”€ step1_load_model.py
â”œâ”€â”€ step2_convert_tflite.py
â”œâ”€â”€ step3_test_tflite.py
â”œâ”€â”€ raspberry_pi_simulation.py
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md

ğŸ› ï¸ Step 1 â€“ Load TensorFlow Model
File: step1_load_model.py
Loads MobileNet model
Verifies model structure
Confirms successful loading

Run:
python step1_load_model.py

ğŸ”„ Step 2 â€“ Convert to TensorFlow Lite
File: step2_convert_tflite.py
Converts SavedModel â†’ .tflite
Optimizes model for edge devices
Saves file as mobilenet_model.tflite

Run:
python step2_convert_tflite.py

ğŸ§ª Step 3 â€“ Test TFLite Model
File: step3_test_tflite.py
Loads .tflite model
Runs dummy input
Prints prediction output

Run:
python step3_test_tflite.py

ğŸ”¹ PART C â€“ Project 2
Edge AI on Raspberry Pi (Simulation)
Since Raspberry Pi hardware was not available, execution was simulated on PC using TensorFlow Lite runtime.

ğŸ¯ Objective
Run TensorFlow Lite model locally simulating Raspberry Pi environment.

âš™ï¸ Task 1 â€“ Install TensorFlow Lite Runtime

On Raspberry Pi (Linux):

sudo apt update
pip install tflite-runtime

On PC (Simulation):
pip install tensorflow

ğŸ§  Task 2 â€“ Load TFLite Model

File: raspberry_pi_simulation.py

interpreter = tf.lite.Interpreter(model_path="mobilenet_model.tflite")
interpreter.allocate_tensors()

ğŸ” Task 3 â€“ Run Inference

Two options:

Option A â€“ Dummy Input (Used)
input_data = np.random.random(input_shape).astype(np.float32)

Option B â€“ Camera Input (Optional)
Using OpenCV:
import cv2

ğŸ“Š Task 4 â€“ Capture and Display Output
Example Output:
Inference successful!
Predicted class index: 885
Confidence: 0.8913

âš¡ Task 5 â€“ Performance Comparison
Feature	PC	Raspberry Pi
CPU Power	High	Limited
RAM	8â€“32GB	2â€“8GB
Inference Speed	Fast	Slower
Use Case	Development	Edge Deployment

ğŸ” Explanation
PC has stronger CPU and more RAM.
Raspberry Pi runs models slower due to hardware limits.
TFLite is optimized for low-power devices.
Edge devices prioritize power efficiency over speed.

ğŸ’» Installation Guide

1ï¸âƒ£ Clone Repository
git clone <your-repo-link>
cd Mobile_Edge_AI_Project

2ï¸âƒ£ Create Virtual Environment
python -m venv venv
venv\Scripts\activate   # Windows

3ï¸âƒ£ Install Dependencies
pip install -r requirements.txt

ğŸ“¦ Requirements
Python 3.10+
TensorFlow
NumPy
(Optional) OpenCV for camera input

ğŸ“ Learning Outcomes
Understanding TensorFlow Lite conversion
Running inference on edge devices
Handling model deployment pipeline
Comparing cloud vs edge performance
Git version control management

ğŸ Final Status
âœ” Model converted successfully
âœ” TFLite model executed successfully
âœ” Inference output generated
âœ” Raspberry Pi simulation completed
âœ” Git repository prepared

ğŸ‘¨â€ğŸ’» Author
Anushka Unhalkar

Outputs: (Screenshots)

![Img1](https://github.com/user-attachments/assets/26d72353-4d84-479e-9eea-ed4cd302212d)

![Img2](https://github.com/user-attachments/assets/b9ccca46-53a8-4f0e-9bd7-73f62accfd64)

![Img3](https://github.com/user-attachments/assets/f121db9e-031b-45ee-84d5-9b4c0802e508)

![Img4](https://github.com/user-attachments/assets/ec14a5d3-a85b-413b-aa06-23bea157722b)

![Img5](https://github.com/user-attachments/assets/2b7b6fe8-9ae1-4da1-8d68-3c7d2d506049)




